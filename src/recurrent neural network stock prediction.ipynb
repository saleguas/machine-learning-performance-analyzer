{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\drale\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates the a\n",
    "def generateGraph(train, test, title, xlabel, ylabel, legend, fileTitle):\n",
    "    ax, fig = plt.subplots(figsize=(10, 8))\n",
    "    fig.plot(train)\n",
    "    fig.plot(test)\n",
    "    fig.set_xlabel(xlabel)\n",
    "    fig.set_ylabel(ylabel)\n",
    "    fig.set_title('{} - {}'.format(title, fileTitle))\n",
    "    fig.legend(legend)\n",
    "    ax.savefig('./graphs/{}.png'.format(fileTitle))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in the csv file with the given path. If split is 0, then it's assumed not to be analyzing and instead predicting future values. \n",
    "def readData(path, split, future):\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.head())\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.set_index('Date')\n",
    "    df = df['Close']\n",
    "    if split > 0:\n",
    "        train = df.iloc[:-split]\n",
    "        test = df.iloc[-split:]\n",
    "        dates = df.index[-split+1:]\n",
    "        return train, test, dates\n",
    "    else:\n",
    "        train = df.iloc[:]\n",
    "        dates = pd.date_range(df.index[-1], periods=future)\n",
    "        return train, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If test is None, that means it will\n",
    "def scaleData(train, test=None, future=None):\n",
    "    sc= MinMaxScaler()\n",
    "    if test != None:\n",
    "        test_sc = sc.transform(test.values.reshape(-1, 1))\n",
    "        train_sc = sc.fit_transform(train.values.reshape(-1, 1))\n",
    "        x_train = train_sc[:-1]\n",
    "        y_train = train_sc[1:]\n",
    "\n",
    "        x_test = test_sc[:-1]\n",
    "        y_test = test_sc[1:]\n",
    "\n",
    "        return x_train, y_train, x_test, y_test, sc\n",
    "    else:\n",
    "        train_sc = sc.fit_transform(train.values.reshape(-1, 1))\n",
    "        x_pred = train_sc[-future:]\n",
    "        x_train = train_sc[:-future]\n",
    "        y_train = train_sc[future:]\n",
    "        return x_train, y_train, x_pred, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(x_train, y_train):\n",
    "    x_train_t = x_train[:, None]\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(6, input_shape=(1, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(x_train_t, y_train, epochs=100, batch_size=16, verbose=1, callbacks=[early_stop])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveSheet(y_pred, y_test, dates, sc, fileName):\n",
    "    df = pd.DataFrame()\n",
    "    y_pred = sc.inverse_transform(y_pred)\n",
    "    df['Date'] = dates\n",
    "    if y_test != None:\n",
    "        y_test = sc.inverse_transform(y_test)\n",
    "        df['Predicted Close'] = y_pred.round(2)\n",
    "        df['Actual Close'] = y_test.round(2)\n",
    "        df['% error'] = ((y_pred - y_test) / y_test*100).round(2)\n",
    "    else:\n",
    "        df['Predicted Close'] = y_pred.round(2)\n",
    "    print(df)\n",
    "    df.to_csv('./results/{}.csv'.format(fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(path, split, fileName):\n",
    "    train, test, dates = readData(path, split)\n",
    "    generateGraph(train,\n",
    "                  test,\n",
    "                  'Training and Testing Data split',\n",
    "                  'Dates',\n",
    "                  'Closing value',\n",
    "                  ['train', 'test'],\n",
    "                  '{}_train_test_split'.format(fileName)\n",
    "                 )\n",
    "    x_train, y_train, x_test, y_test, sc = scaleData(train, test, 1)\n",
    "    model = createModel(x_train, y_train)\n",
    "    x_test_t = x_test[:, None]\n",
    "    y_pred = model.predict(x_test_t)\n",
    "    generateGraph(y_test,\n",
    "                  y_pred,\n",
    "                  'Model results vs Actual value',\n",
    "                  'Future days',\n",
    "                  'Closing Value',\n",
    "                  ['actual', 'predicted'],\n",
    "                  '{}_results'.format(fileName)\n",
    "                 )\n",
    "    print(y_pred.shape, y_test.shape, dates.shape)\n",
    "    saveSheet(y_pred, y_test, dates, sc, fileName)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path, future, fileName):\n",
    "    train, dates = readData(path, 0, 20)\n",
    "    x_train, y_train, pred,sc = scaleData(train, test=None, future=future)\n",
    "    model = createModel(x_train, y_train)\n",
    "    pred = pred[:, None]\n",
    "    y_pred = model.predict(pred)\n",
    "    saveSheet(y_pred, None, dates, sc, \"TestPredict\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAnalyze():\n",
    "    import os\n",
    "    for filename in os.listdir('./data'):\n",
    "        analyze('./data/{}'.format(filename), 180, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Open   High    Low    Close       Volume  Ex-Dividend  \\\n",
      "0  2012-05-18  42.05  45.00  38.00  38.2318  573576400.0          0.0   \n",
      "1  2012-05-21  36.53  36.66  33.00  34.0300  168192700.0          0.0   \n",
      "2  2012-05-22  32.61  33.59  30.94  31.0000  101786600.0          0.0   \n",
      "3  2012-05-23  31.37  32.50  31.36  32.0000   73600000.0          0.0   \n",
      "4  2012-05-24  32.95  33.21  31.77  33.0300   50237200.0          0.0   \n",
      "\n",
      "   Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume  \n",
      "0          1.0      42.05      45.00     38.00     38.2318  573576400.0  \n",
      "1          1.0      36.53      36.66     33.00     34.0300  168192700.0  \n",
      "2          1.0      32.61      33.59     30.94     31.0000  101786600.0  \n",
      "3          1.0      31.37      32.50     31.36     32.0000   73600000.0  \n",
      "4          1.0      32.95      33.21     31.77     33.0300   50237200.0  \n",
      "------------------------------------------------------------------\n",
      "Epoch 1/100\n",
      "1452/1452 [==============================] - 1s 378us/step - loss: 0.2140\n",
      "Epoch 2/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0963\n",
      "Epoch 3/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0522\n",
      "Epoch 4/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0388\n",
      "Epoch 5/100\n",
      "1452/1452 [==============================] - 0s 131us/step - loss: 0.0309\n",
      "Epoch 6/100\n",
      "1452/1452 [==============================] - 0s 129us/step - loss: 0.0234\n",
      "Epoch 7/100\n",
      "1452/1452 [==============================] - 0s 131us/step - loss: 0.0164\n",
      "Epoch 8/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0105\n",
      "Epoch 9/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0062\n",
      "Epoch 10/100\n",
      "1452/1452 [==============================] - 0s 157us/step - loss: 0.0035\n",
      "Epoch 11/100\n",
      "1452/1452 [==============================] - 0s 167us/step - loss: 0.0021\n",
      "Epoch 12/100\n",
      "1452/1452 [==============================] - 0s 139us/step - loss: 0.0016\n",
      "Epoch 13/100\n",
      "1452/1452 [==============================] - 0s 131us/step - loss: 0.0014\n",
      "Epoch 14/100\n",
      "1452/1452 [==============================] - 0s 129us/step - loss: 0.0013\n",
      "Epoch 15/100\n",
      "1452/1452 [==============================] - 0s 129us/step - loss: 0.0013\n",
      "Epoch 16/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0013\n",
      "Epoch 17/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0013\n",
      "Epoch 18/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0012\n",
      "Epoch 19/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0012\n",
      "Epoch 20/100\n",
      "1452/1452 [==============================] - 0s 129us/step - loss: 0.0012\n",
      "Epoch 21/100\n",
      "1452/1452 [==============================] - 0s 128us/step - loss: 0.0012\n",
      "Epoch 22/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0012\n",
      "Epoch 23/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0012\n",
      "Epoch 24/100\n",
      "1452/1452 [==============================] - 0s 130us/step - loss: 0.0012\n",
      "Epoch 25/100\n",
      "1452/1452 [==============================] - 0s 132us/step - loss: 0.0012\n",
      "Epoch 26/100\n",
      "1452/1452 [==============================] - 0s 132us/step - loss: 0.0012\n",
      "Epoch 27/100\n",
      "1452/1452 [==============================] - 0s 125us/step - loss: 0.0011\n",
      "Epoch 28/100\n",
      "1452/1452 [==============================] - 0s 132us/step - loss: 0.0011\n",
      "Epoch 29/100\n",
      "1452/1452 [==============================] - 0s 126us/step - loss: 0.0011\n",
      "Epoch 30/100\n",
      "1452/1452 [==============================] - 0s 127us/step - loss: 0.0011\n",
      "Epoch 31/100\n",
      "1452/1452 [==============================] - 0s 132us/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "1452/1452 [==============================] - 0s 166us/step - loss: 0.0011\n",
      "Epoch 33/100\n",
      "1452/1452 [==============================] - 0s 155us/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "1452/1452 [==============================] - 0s 154us/step - loss: 0.0011\n",
      "Epoch 35/100\n",
      "1452/1452 [==============================] - 0s 147us/step - loss: 0.0011\n",
      "Epoch 00035: early stopping\n",
      "         Date  Predicted Close\n",
      "0  2018-03-27       181.070007\n",
      "1  2018-03-28       178.880005\n",
      "2  2018-03-29       179.500000\n",
      "3  2018-03-30       182.970001\n",
      "4  2018-03-31       182.399994\n",
      "5  2018-04-01       185.970001\n",
      "6  2018-04-02       184.729996\n",
      "7  2018-04-03       187.339996\n",
      "8  2018-04-04       186.919998\n",
      "9  2018-04-05       184.309998\n",
      "10 2018-04-06       186.399994\n",
      "11 2018-04-07       186.100006\n",
      "12 2018-04-08       187.210007\n",
      "13 2018-04-09       175.750000\n",
      "14 2018-04-10       171.619995\n",
      "15 2018-04-11       172.779999\n",
      "16 2018-04-12       168.529999\n",
      "17 2018-04-13       163.279999\n",
      "18 2018-04-14       163.919998\n",
      "19 2018-04-15       156.289993\n"
     ]
    }
   ],
   "source": [
    "predict('./data/WIKI_FB.csv', 20, 'WIKI_FB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>shift1</th>\n",
       "      <th>shift-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original  shift1  shift-1\n",
       "0         1     NaN      2.0\n",
       "1         2     1.0      3.0\n",
       "2         3     2.0      4.0\n",
       "3         4     3.0      5.0\n",
       "4         5     4.0      NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame()\n",
    "d['Original'] = [1, 2, 3, 4, 5]\n",
    "d['shift1'] = d['Original'].shift(1)\n",
    "d['shift-1'] = d['Original'].shift(-1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
